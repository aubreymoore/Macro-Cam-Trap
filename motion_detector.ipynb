{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motion Detector\n",
    "\n",
    "This Jupyter notebook should be opened using the following commands:\n",
    "~~~bash\n",
    "    workon jupyter\n",
    "    jupyter notebook\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import sys\n",
    "import glob\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initiate_logger():\n",
    "    logger = logging.getLogger()\n",
    "    handler = logging.StreamHandler()\n",
    "    #formatter = logging.Formatter('%(asctime)s %(name)-12s %(levelname)-8s %(message)s')\n",
    "    formatter = logging.Formatter('%(asctime)s %(levelname)-8s %(message)s')\n",
    "    handler.setFormatter(formatter)\n",
    "    logger.addHandler(handler)\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def motion_detector():\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='Motion detector.\\\n",
    "        When one or more objects in motion are detected in a video frame,\\\n",
    "        the frame is saved as a jpg and bounding box coordinates are added to a dataframe.\\\n",
    "        When the video has been processed, the dataframe is saved as a CSV file\\\n",
    "        and the original video is optionally deleted to save storage space.')\n",
    "\n",
    "    parser.add_argument('data_dir',\n",
    "                        type=str,\n",
    "                        help='data directory (without trailing /) \\\n",
    "                        Example: /media/aubrey/9016-4EF8/ants')\n",
    "\n",
    "    parser.add_argument('video_file',\n",
    "                        type=str,\n",
    "                        help='video_file name \\\n",
    "                        Example: VID_20190810_120737.mp4')\n",
    "\n",
    "    parser.add_argument('--frame_size_factor',\n",
    "                        default=4,\n",
    "                        help='the frame size is shrunken by this factor before \\\n",
    "                        motion detection is performed to speed up processing \\\n",
    "                        (default=4).')\n",
    "\n",
    "    parser.add_argument('--min_area',\n",
    "                        default=0.001,\n",
    "                        help='minimum size of moving object in relation to area of full frame \\\n",
    "                        frame (default=0.001)')\n",
    "\n",
    "    parser.add_argument('--keep_video',\n",
    "                        default='true',\n",
    "                        help='keep the original video after processing?')\n",
    "\n",
    "    parser.add_argument('--skip_frames',\n",
    "                        default=10,\n",
    "                        help='number of frames to skip at start of recording')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    video_file_path = '{}/{}'.format(args.data_dir, args.video_file)\n",
    "    vs = cv2.VideoCapture(video_file_path)\n",
    "    original_frame_width = vs.get(3)\n",
    "    original_frame_height = vs.get(4)\n",
    "    detection_frame_width = int(original_frame_width / args.frame_size_factor)\n",
    "    detection_frame_height = int(original_frame_height / args.frame_size_factor)\n",
    "    detection_minimum_area = int(args.min_area * detection_frame_width * detection_frame_height)\n",
    "    skip_frames = args.skip_frames\n",
    "\n",
    "    # Create a directory for frames in which motion is detected\n",
    "    frames_dir = '{}/frames'.format(args.data_dir)\n",
    "    if not os.path.exists(frames_dir):\n",
    "        os.makedirs(frames_dir)\n",
    "\n",
    "    # Create an empty dataframe to store bounding boxes for objects in motion\n",
    "    df = pd.DataFrame(columns=['filename', 'xtl', 'ytl', 'xbr', 'ybr'])\n",
    "\n",
    "    fgbg = cv2.createBackgroundSubtractorMOG2(varThreshold=50, detectShadows=True)\n",
    "\n",
    "    # loop over the frames of the video\n",
    "    logger.debug('Starting motion detector on {}'.format(args.video_file))\n",
    "    framenum = 0\n",
    "    avg = None\n",
    "    while True:\n",
    "        # grab the current frame\n",
    "        frame = vs.read()\n",
    "        frame = frame[1]\n",
    "\n",
    "        # If we are at the end of the file, the frame will be empty, so break out of the loop.\n",
    "        if frame is None:\n",
    "            break\n",
    "\n",
    "        # Increment the frame count and print every 100 frames to indicate progress.\n",
    "        framenum += 1\n",
    "        if (framenum % 1000) == 0:\n",
    "            logger.debug('{} frames processed'.format((framenum)))\n",
    "\n",
    "        # Make a copy of the original frame and resize it\n",
    "        original_frame = frame\n",
    "        frame = imutils.resize(frame, width=detection_frame_width)\n",
    "\n",
    "        # Perform background subtraction\n",
    "        thresh = fgbg.apply(frame)\n",
    "        #thresh[thresh==127]=0 # Set shadows (127) to black (0)\n",
    "\n",
    "        # Find contours on thresholded image\n",
    "        cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnts = imutils.grab_contours(cnts)\n",
    "\n",
    "        if framenum > skip_frames: \n",
    "            # loop over the contours\n",
    "            bbfound = False\n",
    "            for c in cnts:\n",
    "                # if the contour is too small, ignore it\n",
    "                if cv2.contourArea(c) > detection_minimum_area:\n",
    "                    bbfound = True\n",
    "\n",
    "                    # compute the bounding box for the contour with coordinates\n",
    "                    # expressed as proportion of width and height of frame\n",
    "                    (x, y, w, h) = cv2.boundingRect(c)\n",
    "                    xtl = x / detection_frame_width\n",
    "                    ytl = y / detection_frame_height\n",
    "                    xbr = (x+w) / detection_frame_width\n",
    "                    ybr = (y+h) / detection_frame_height\n",
    "                    filename = '{}/frames/{}f{:0>6}.jpg'.format(args.data_dir, args.video_file.split('.')[0], framenum)\n",
    "                    #print('mob {} {:f} {:f} {:f} {:f}'.format(filename, xtl, ytl, xbr, ybr))\n",
    "                    df = df.append({'filename': filename,\n",
    "                                    'xtl': xtl,\n",
    "                                    'ytl': ytl,\n",
    "                                    'xbr': xbr,\n",
    "                                    'ybr': ybr},\n",
    "                                    ignore_index=True)\n",
    "            # if one or more moving objects were detected, save the original frame\n",
    "            if bbfound:\n",
    "                cv2.imwrite(filename, original_frame)\n",
    "\n",
    "    # Save the dataframe as a CSV        \n",
    "    filename ='{}/{}_bounding_boxes.csv'.format(args.data_dir, args.video_file.split('.')[0])\n",
    "    logger.debug('Saving ' + filename)\n",
    "    df.to_csv(filename, index=False)\n",
    "\n",
    "    vs.release()\n",
    "\n",
    "    if args.keep_video=='false':\n",
    "        os.remove(video_file)\n",
    "        logger.debug('{} deleted'.format(video_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-25 18:16:45,880 DEBUG    Starting motion detector on VID_20190810_120737.mp4\n",
      "2019-08-25 18:17:04,419 DEBUG    1000 frames processed\n",
      "2019-08-25 18:17:15,895 DEBUG    Saving data/ants/VID_20190810_120737/VID_20190810_120737_bounding_boxes.csv\n",
      "2019-08-25 18:17:15,913 DEBUG    Finished\n"
     ]
    }
   ],
   "source": [
    "# MAIN\n",
    "\n",
    "logger = initiate_logger()\n",
    "\n",
    "# Uncomment the following line to test code within a Jupyter notebook\n",
    "sys.argv = ['motion_detector.py', 'data/ants/VID_20190810_120737', 'VID_20190810_120737.mp4']\n",
    "\n",
    "motion_detector()\n",
    "\n",
    "logger.debug('Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook motion_detector.ipynb to script\n",
      "[NbConvertApp] Writing 6543 bytes to motion_detector.py\n"
     ]
    }
   ],
   "source": [
    "# Uncomment the following line to create a pure python script called motion_detector.py\n",
    "!jupyter nbconvert --to=script 'motion_detector'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
